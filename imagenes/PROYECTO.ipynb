{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673efbf9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">0. Conceptos previos</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22b9d0",
   "metadata": {},
   "source": [
    "Antes de empezar a programar es importante tener claro qué problema se quiere resolver. En este proyecto la idea principal es que una computadora pueda aprender a tomar decisiones usando datos numéricos, o sea que pueda identificar a qué categoría pertenece cada ejemplo. Esto corresponde a un problema de <span style=\"color:#FFEB3B; font-weight:bold;\"> clasificación supervisada </span> porque durante el entrenamiento ya se conoce la respuesta correcta de cada dato. El modelo no inventa nuevas clases sino que aprende a elegir una de las que ya existen. En el caso del <span style=\"color:#FFEB3B; font-weight:bold;\"> dataset CoverType </span> la variable objetivo indica distintos tipos de cobertura forestal. Como hay <span style=\"color:#FFEB3B; font-weight:bold;\"> siete tipos posibles </span> y cada muestra pertenece solo a uno se trata de un problema de <span style=\"color:#FFEB3B; font-weight:bold;\"> clasificación multiclase supervisada</span>.\n",
    "\n",
    "Los datos vienen organizados en un dataset que puede verse como una tabla grande. Cada fila representa una muestra y cada columna una característica que describe esa muestra, o sea los <span style=\"color:#FFEB3B; font-weight:bold;\"> features</span>. Entre estas características hay datos como la elevación del terreno, la pendiente, la distancia a ríos o carreteras y otros valores numéricos. Además existe una columna especial que indica la clase correcta de cada muestra, conocida como <span style=\"color:#FFEB3B; font-weight:bold;\"> label </span>. Todas las demás columnas forman el conjunto de datos de entrada que el modelo usará para aprender.\n",
    "\n",
    "Antes de entrenar el modelo, se realiza una exploración de los datos <span style=\"color:#FFEB3B; font-weight:bold;\"> (EDA).</span> En esta etapa se revisa cuántos datos hay, cuántas variables tiene cada muestra, cómo están distribuidas las clases y si existe algún desbalance entre ellas. También se observan los rangos de los valores numéricos, esto es muy importante. Un problema común es que algunas variables tengan valores muy grandes y otras muy pequeños, esto puede afectar el aprendizaje del modelo. Para evitar esto, se aplica una <span style=\"color:#FFEB3B; font-weight:bold;\"> normalización o estandarización </span>  con el fin de que todas las variables estén en escalas similares y el entrenamiento sea más estable.\n",
    "\n",
    "Luego de preparar los datos se construye el modelo. En este proyecto se utiliza una red neuronal artificial formada por varias capas. Cada capa combina los valores de entrada mediante <span style=\"color:#FFEB3B; font-weight:bold;\"> pesos</span>, suma un <span style=\"color:#FFEB3B; font-weight:bold;\"> sesgo</span>  y aplica una <span style=\"color:#FFEB3B; font-weight:bold;\"> función de activación</span> . *Esta función permite que el modelo aprenda relaciones más complejas y no solo relaciones lineales simples.*\n",
    "\n",
    "La arquitectura utilizada es un <span style=\"color:#FFEB3B; font-weight:bold;\"> MLP (Multi-Layer Perceptron)</span>. Este tipo de red neuronal es <span style=\"color:#FFEB3B; font-weight:bold;\"> feed-forward </span>, lo que significa que la información va desde la entrada hasta la salida sin retroceder. Está compuesta por una o más capas ocultas completamente conectadas. *Los MLP son modelos relativamente simples*, pero funcionan bien con datos tabulares como los del dataset **CoverType**. A diferencia de otros modelos más especializados, como las redes convolucionales para imágenes o las redes recurrentes para datos secuenciales, el MLP es una opción adecuada para este problema.\n",
    "\n",
    "Para ubicar mejor a esta arquitectura, con ayuda de chat gpt hice este mapa mental. \n",
    "\n",
    "![Mapa mental](https://raw.githubusercontent.com/Josueeeoo-0/redes-neuronales-notebook-SIAFI/cc78f3207dc6d5f87fd6ead6eb92b11e58ae1948/imagenes/Mind%20Map%20Whiteboard%20in%20Blue%20and%20Yellow%20Simple%20Brainstorm%20Style%20(1).png)\n",
    "\n",
    "\n",
    "Para que la red aprenda se define una <span style=\"color:#FFEB3B; font-weight:bold;\"> función de pérdida</span> que mide qué tan lejos está la predicción del modelo de la respuesta real. En problemas de clasificación multiclase se usa comúnmente la <span style=\"color:#FFEB3B; font-weight:bold;\"> entropía cruzada</span>. Durante el entrenamiento, el modelo hace una predicción, se calcula el error y luego se ajustan los pesos para reducir ese error. Este proceso se realiza mediante el <span style=\"color:#FFEB3B; font-weight:bold;\"> algoritmo de backpropagation</span>. <span style=\"color:#FFEB3B; font-weight:bold;\"> PyTorch </span>  **se encarga de automatizar estos cálculos, lo que facilista la implementación del modelo.**\n",
    "\n",
    "**Todo el desarrollo se realiza usando PyTorch, una librería muy utilizada para aprendizaje profundo**. PyTorch trabaja con <span style=\"color:#FFEB3B; font-weight:bold;\"> tensores </span> *que son similares a los arrays de NumPy*, pero están optimizados para este tipo de cálculos. Además, permite usar tanto la <span style=\"color:#FFEB3B; font-weight:bold;\">CPU </span> como la <span style=\"color:#FFEB3B; font-weight:bold;\"> GPU </span>. La GPU es especialmente útil porque puede realizar muchos cálculos en paralelo, lo que reduce el tiempo de entrenamiento, sobre todo cuando se trabaja con grandes cantidades de datos.\n",
    "\n",
    "Una vez entrenado el model se evalúa usando datos que no fueron utilizados durante el entrenamiento. El objetivo es verificar qué tan bien generaliza el modelo a datos nuevos. Una métrica común es la <span style=\"color:#FFEB3B; font-weight:bold;\"> accuaracy</span> que indica el porcentaje de predicciones correctas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f48a1a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">1. El dataset CoverType</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1df98f",
   "metadata": {},
   "source": [
    "Antes de entrenar cualquier red neuronal necesitamos saber qué información tenemoss. El dataset CoverType es un conjunto de datos reales que describe diferentes zonas de bosque en Estados Unidos. Cada fila del dataset representa un área específica de terreno, y el objetivo es predecir qué tipo de cobertura forestal hay en esa zona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed1c1a",
   "metadata": {},
   "source": [
    "Cuando hablamos de *\"cobertura forestal\"* nos referimos a categorías como pino, abeto, bosque mixto, etc. En total el dataset tiene 7 tipos distintos de cobertura y cada uno de ellos será una clase diferente que el modelo deberá aprender a identificar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e08be0",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">1.1 ¿Qué contiene exactamente el dataset y que significan?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af681e63",
   "metadata": {},
   "source": [
    "El dataset CoverType está compuesto por dos partes principales: las features (características de entrada) y el label (la clase que queremos predecir)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb2b18",
   "metadata": {},
   "source": [
    "Las <span style=\"color:#FFEB3B; font-weight:bold;\"> features</span> **son variables numéricas que describen el terreno. El dataset CoverType tiene 54 features en total. Se dividen en 4 grupos.**. \n",
    "\n",
    "Por ejemplo, algunas indican la elevación del suelo, otras la pendiente, otras la distancia a ríos o carreteras. También hay un grupo de variables binarias (solo 0 o 1) que representan el tipo de suelo. Cada una de estas variables aporta un poco de información y juntas forman una descripción completa del lugar.\n",
    "\n",
    "Entonces cada fila representa un solo punto del terreno. Ese punto tiene características físicas como la elevación, la pendiente o la orientación, y además pertenece a una sola categoría de ciertas variables, como el tipo de suelo y el área silvestre. No puede pertenecer a varias categorías al mismo tiempo.\n",
    "\n",
    "En la realidad, un terreno solo puede tener un tipo de suelo dominante, no varios a la vez. Como los modelos de machine learning trabajan con números, esa categoría se transforma usando una técnica llamada <span style=\"color:#FFEB3B; font-weight:bold;\"> one-hot encoding</span> que consiste en crear una columna por cada tipo posible de suelo.\n",
    "\n",
    "Por eso existen columnas como `Soil_Type_1`, `Soil_Type_2`, …, `Soil_Type_40`. Si el terreno corresponde al suelo tipo 14, entonces la columna `Soil_Type_14` toma el valor 1, indicando “este es el suelo presente”, y todas las demás columnas de suelo valen 0, indicando \"este suelo no está presente\". Solo una columna puede valer 1 porque el terreno no puede tener dos suelos distintos al mismo tiempo.\n",
    "\n",
    "Lo mismo ocurre con las columnas `Wilderness_Area_1` a `Wilderness_Area_4`. Cada punto del terreno se encuentra en una sola área silvestre, así que únicamente una de esas columnas será 1 y las demás serán 0. De nuevo, el 1 significa “sí pertenece” y el 0 significa “no pertenece”.\n",
    "\n",
    "**Esta representación se usa porque no existe un orden numérico real entre los tipos de suelo o las áreas silvestres. Si se usara un solo número (por ejemplo, suelo = 14), el modelo podría interpretar erróneamente que el suelo 14 es \"mayor\" o \"mejor\" que el suelo 5, cuando en realidad solo son categorías distintas sin jerarquía.**\n",
    "\n",
    "Es por eso que:\n",
    "- **Variables numéricas (10)**\n",
    "\n",
    "| Nº | Feature                            |\n",
    "| -: | ---------------------------------- |\n",
    "|  1 | Elevation                          |\n",
    "|  2 | Aspect                             |\n",
    "|  3 | Slope                              |\n",
    "|  4 | Horizontal_Distance_To_Hydrology   |\n",
    "|  5 | Vertical_Distance_To_Hydrology     |\n",
    "|  6 | Horizontal_Distance_To_Roadways    |\n",
    "|  7 | Hillshade_9am                      |\n",
    "|  8 | Hillshade_Noon                     |\n",
    "|  9 | Hillshade_3pm                      |\n",
    "| 10 | Horizontal_Distance_To_Fire_Points |\n",
    "\n",
    "- **Wilderness Area (One-Hot Encoding, 4)**\n",
    "\n",
    "| Nº | Feature           |\n",
    "| -: | ----------------- |\n",
    "| 11 | Wilderness_Area_1 |\n",
    "| 12 | Wilderness_Area_2 |\n",
    "| 13 | Wilderness_Area_3 |\n",
    "| 14 | Wilderness_Area_4 |\n",
    "\n",
    "- **Soil Type (One-Hot Encoding, 40)**\n",
    "\n",
    "| Nº | Feature      |\n",
    "| -: | ------------ |\n",
    "| 15 | Soil_Type_1  |\n",
    "| 16 | Soil_Type_2  |\n",
    "| 17 | Soil_Type_3  |\n",
    "| 18 | Soil_Type_4  |\n",
    "| 19 | Soil_Type_5  |\n",
    "| 20 | Soil_Type_6  |\n",
    "| .. | ...........  |\n",
    "| 54 | Soil_Type_40 |\n",
    "\n",
    "\n",
    "\n",
    "El <span style=\"color:#FFEB3B; font-weight:bold;\"> label </span> en cambio es un número entero entre 1 y 7 que indica el tipo de cobertura forestal. Este número es lo que el modelo debe aprender a predecir. Durante el entrenamiento el modelo ve tanto las features como el label, pero durante la evaluación, solo ve las features y debe adivinar el label.\n",
    "\n",
    "| Label | Tipo de cobertura forestal                                          |\n",
    "| ----: | ------------------------------------------------------------------- |\n",
    "| **1** | **Spruce / Fir** (Abeto / Pícea)                                    |\n",
    "| **2** | **Lodgepole Pine** (Pino contorta)                                  |\n",
    "| **3** | **Ponderosa Pine** (Pino ponderosa)                                 |\n",
    "| **4** | **Cottonwood / Willow** (Álamo / Sauce)                             |\n",
    "| **5** | **Aspen** (Álamo temblón)                                           |\n",
    "| **6** | **Douglas-fir** (Abeto de Douglas)                                                     |\n",
    "| **7** | **Krummholz** (árboles deformados por clima extremo, zonas alpinas) |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Esto es lo que hace que el problema sea de aprendizaje supervisado: tenemos ejemplos con respuesta correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880bfead",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">1.2 Cargamos el dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53f47d",
   "metadata": {},
   "source": [
    "Para trabajar con el dataset usamos una función de scikit-learn que ya descarga y organiza los datos por nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deeee0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "data = fetch_covtype()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1da30",
   "metadata": {},
   "source": [
    "La variable `X` contiene las features, es decir, todos los datos de entrada. Es una matriz donde cada fila es una muestra y cada columna es una feature. La variable `y` contiene los labels, es decir, la clase correcta de cada muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13036122",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">1.3 Tamaño y dimensionalidad del dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2bdc3",
   "metadata": {},
   "source": [
    "¿Qué tan grande es este dataset?. Esto importa mucho, porque entrenar redes neuronales con pocos datos suele ser mala idea, mientras que datasets grandes suelen beneficiarse más del deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6e18b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581012, 54)\n",
      "(581012,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc861e56",
   "metadata": {},
   "source": [
    "El resultado indica que el dataset CoverType contiene un total de 581 012 muestras, donde cada muestra está representada por 54 características, mientras que el vector de etiquetas tiene una clase asociada para cada ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2aa945",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">1.4 ¿Qué significan estas features?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da2197",
   "metadata": {},
   "source": [
    "Las primeras columnas suelen ser variables continuas, como elevación o distancia. Más adelante aparecen columnas binarias que indican pertenencia a ciertos tipos de suelo. \n",
    "\n",
    "Esto tiene una consecuencia importante: no todas las features están en la misma escala. Algunas pueden tomar valores grandes otras solo 0 o 1. Esto nos lleva a la idea de que más adelante necesitaremos <span style=\"color:#FFEB3B; font-weight:bold;\"> normalizar </span> los datos antes de entrenar la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f54f35",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">1.5 Distribución de las clases</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68452b",
   "metadata": {},
   "source": [
    "Otro aspecto clave es ver cuántos ejemplos hay de cada clase, o sea de las 7 que hay, cuantas muestras le pertenecen a cada clase de las 5481 012 muestras que hay. Esto se llama la <span style=\"color:#FFEB3B; font-weight:bold;\"> distribución de clases </span> y nos ayuda a detectar si el dataset está balanceado o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f0faf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7], dtype=int32),\n",
       " array([211840, 283301,  35754,   2747,   9493,  17367,  20510]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(y, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a3217",
   "metadata": {},
   "source": [
    "El resultado muestra que el dataset CoverType contiene 7 clases (etiquetadas del 1 al 7) con una distribución claramente desigual: las clases 2 y 1 concentran la mayoría de los ejemplos (283 301 y 211 840 respectivamente) mientras que otras clases como la 4 (solo 2 747 muestras) y la 5 (9 493 muestras) están muy poco representadas. \n",
    "\n",
    "Esto revela que el dataset está desbalanceado, esto hace que un modelo entrenado directamente podría tender a favorecer las clases dominantes y obtener una <span style=\"color:#FFEB3B; font-weight:bold;\">accuracy</span> aparentemente alta sin necesariamente comportarse bien en las clases de menor muestras. Pero dado el gran tamaño total del dataset y que incluso las clases pequeñas tienen miles de ejemplos, resulta aceptable para este caso, sin aplicar técnicas de balanceo.\n",
    "\n",
    "Pero tengamos en cuenta que existen correcciones (como <span style=\"color:#FFEB3B; font-weight:bold;\"> ponderación de clases </span>  o <span style=\"color:#FFEB3B; font-weight:bold;\">resampling</span>) para fases posteriores del modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d82cce",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">2. Preprocesamiento de datos: preparando la información para la red neuronal</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb695f",
   "metadata": {},
   "source": [
    "Hasta ahora solo hemos cargado y observado el dataset. Eso nos permitió entender qué tipo de problema tenemos y cómo están organizados los datos, pero todavía no están listos para entrar a una red neuronal. Esta etapa se llama preprocesamiento, y consiste en transformar los datos crudos en una forma digerible para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f5fc4",
   "metadata": {},
   "source": [
    "Una red neuronal no responde bien cuando las variables están en escalas muy distintas o cuando los datos presentan distribuciones extremas. Si el modelo recibe características desbalanceadas o mal normalizadas, el proceso de entrenamiento puede volverse inestable, lo que lleva a que la red aprenda relaciones que no representan el problema real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d4f16",
   "metadata": {},
   "source": [
    "En nuestro caso, ya vimos que algunas features toman valores grandes (como elevación o distancias), mientras que otras son binarias (0 o 1). Si dejamos todo tal cual, las variables grandes dominarán el aprendizaje solo por su valor o magnitud. Para evitar esto, vamos a aplicar una transformación llamada <span style=\"color:#FFEB3B; font-weight:bold;\"> estandarización </span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018dbb8",
   "metadata": {},
   "source": [
    "Estandarizar significa transformar cada feature para que tenga media cero y desviación estándar uno. En palabras simples: todas las columnas quedan centradas y con una escala comparable. Esto no cambia la información esencial de los datos, pero hace que el entrenamiento sea mucho más eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d2d08",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">2.1 Normalización (StandardScaler)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3f93d",
   "metadata": {},
   "source": [
    "Vamos a usar StandardScaler de scikit-learn, que implementa exactamente esta transformación. **Lo usamos en el archivo *2_3_2_classfication_algorithms* para estandarizar el data set de iris.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed37a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a3d45",
   "metadata": {},
   "source": [
    "Aquí ocurren dos cosas importantes.\n",
    "\n",
    "Primero, `fit_transform` calcula la media y la desviación estándar de cada feature usando todo X, y luego aplica la transformación. El resultado es `X_scaled`, que contiene los mismos datos que X, pero ahora normalizados.\n",
    "\n",
    "Segundo, guardamos el objeto `scaler`. Esto es importante porque más adelante, si tuviéramos datos nuevos, deberíamos usar el mismo `scaler` para transformarlos.\n",
    "\n",
    "Conceptualmente, en este punto ya tenemos los mismos datos pero expresados en una forma matemática más amigable para una red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db7fc3",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">2.2 Separación en conjuntos: entrenamiento, validación y prueba</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9097a",
   "metadata": {},
   "source": [
    "Sabemos perfectamente que no podemos entrenar y evaluar usando los mismos datos. Si lo hiciéramos, el modelo podría simplemente memorizar los ejemplos y parecer perfecto, aunque en realidad no generalice a datos nuevos. Para evitar esto, dividimos el dataset en tres partes:\n",
    "\n",
    "- Entrenamiento (train): aquí el modelo aprende.\n",
    "- Validación (validation): aquí ajustamos hiperparámetros y observamos el comportamiento durante el entrenamiento.\n",
    "- Prueba (test): aquí evaluamos el resultado final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeecd41",
   "metadata": {},
   "source": [
    "Primero separamos un conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ae39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3b331",
   "metadata": {},
   "source": [
    "Esto deja el 80% de los datos para entrenamiento + validación y el 20% para prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f232e0",
   "metadata": {},
   "source": [
    "Luego dividimos ese 80% en entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77dd02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd99f983",
   "metadata": {},
   "source": [
    "Ahora tenemos tres conjuntos bien definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e532b",
   "metadata": {},
   "source": [
    "Desde el punto de vista conceptual, esto significa que el modelo verá `X_train` muchas veces durante el entrenamiento, verá `X_val` ocasionalmente para verificar cómo va aprendiendo, y solo verá `X_test` una vez al final, para medir su desempeño real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65177a3",
   "metadata": {},
   "source": [
    "PERO, ¿PORQUE ACA NO <span style=\"color:#FFEB3B; font-weight:bold;\"> ESTRATIFICAMOS </span> *el dataset así como lo **hicimos con el PROYECTO A2B - n°1***?\n",
    "\n",
    "En este caso, con el dataset CoverType estamos usando una división aleatoria normal porque estamos trabajando con muchísimos datos: más de medio millón de muestras y miles de ejemplos incluso en las clases más pequeñas. Con un volumen así, al hacer un split aleatorio las proporciones de cada clase se conservan casi automáticamente, por simple estadística. Además, aquí no existen identidades específicas como personas, sino observaciones independientes, por lo que no hay riesgo real de que alguna clase desaparezca o quede mal representada.\n",
    "\n",
    "En cambio, con datasets pequeños como Olivetti Faces la historia es distinta. Cada persona solo tiene unas pocas imágenes, así que si dividimos al azar es muy fácil que algunas aparezcan poco en entrenamiento, casi nada en prueba, o incluso que no aparezcan en alguno de los conjuntos. Eso hace que la evaluación sea poco confiable. Por eso se usa  <span style=\"color:#FFEB3B; font-weight:bold;\">muestreo estratificado</span>: para asegurarnos de que cada persona tenga una cantidad similar de imágenes tanto en entrenamiento como en prueba.\n",
    "\n",
    "No es que uno sea \"mejor\" que el otro sino que depende del contexto. Cuando el dataset es grande, como CoverType, una división simple funciona bien. Pero cuando el dataset es pequeño y sensible al desbalance, como en reconocimiento facial, el muestreo estratificado se vuelve necesario para que el modelo aprenda y se evalúe de forma justa.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b8cb0",
   "metadata": {},
   "source": [
    "ME PARECIO INTERESANTE HACER ESA DIFERENCIA :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b4c8b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">2.3 De NumPy a PyTorch: tensores</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f13bb",
   "metadata": {},
   "source": [
    "Hasta ahora hemos trabajado con arrays de NumPy, pero PyTorch usa su propia estructura de datos llamada <span style=\"color:#FFEB3B; font-weight:bold;\">tensor</span>. Un array se entiende como tabla de números organizada en filas y columnas (o en más dimensiones), que permite almacenar y manipular datos de forma eficiente en Python, y es la base de muchas operaciones numéricas en ciencia de datos. Sin embargo, PyTorch utiliza tensores, que son muy parecidos a los arrays, pero tienen dos ventajas clave: <span style=\"color:#FFEB3B; font-weight:bold;\">pueden ejecutarse directamente en la GPU </span> y pueden <span style=\"color:#FFEB3B; font-weight:bold;\">participar en cálculos automáticos de gradientes</span>. Por eso ahora convertimos todo a tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabd4b",
   "metadata": {},
   "source": [
    "Para las entradas `(X_train, X_val, X_test)` usamos `dtype=torch.float32`, que es el tipo estándar para datos numéricos en redes neuronales y permite realizar operaciones de forma eficiente tanto en CPU como en GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511d8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_t   = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c874bcb",
   "metadata": {},
   "source": [
    "Luego convertimos las etiquetas `(y_train, y_val, y_test)` a tensores de tipo `torch.long`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a598c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t = torch.tensor(y_train - 1, dtype=torch.long)\n",
    "y_val_t   = torch.tensor(y_val - 1, dtype=torch.long)\n",
    "y_test_t  = torch.tensor(y_test - 1, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e09bbc",
   "metadata": {},
   "source": [
    "Aquí aparecen dos detalles importantes. Primero, restamos 1 a las etiquetas porque el dataset CoverType numera las clases del 1 al 7, mientras que PyTorch espera que las clases comiencen en 0. De esta forma, las etiquetas pasan a ser 0, 1, 2, 3, 4, 5 y 6 evitando errores al usar funciones de pérdida como <span style=\"color:#FFEB3B; font-weight:bold;\">CrossEntropyLoss</span> .\n",
    "\n",
    "Segundo, usamos `torch.long` para las etiquetas porque PyTorch requiere este tipo de dato entero para representar clases en problemas de clasificación. Y esto es importante porque funciones como: `torch.nn.CrossEntropyLoss()` solo aceptan etiquetas en formato entero (long) ya que internamente usan esos valores como índices de clase. En cambio, las variables de entrada se mantienen como float32, ya que las capas de la red neuronal trabajan con valores reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28dfd72",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">2.4 Dataset y DataLoader: alimentando datos al modelo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc568a7d",
   "metadata": {},
   "source": [
    "Aunque ya contamos con los datos en forma de tensores, PyTorch trabaja de manera más eficiente cuando utilizamos dos estructuras clave: <span style=\"color:#FFEB3B; font-weight:bold;\">Dataset</span> y <span style=\"color:#FFEB3B; font-weight:bold;\">DataLoader</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4dbbec",
   "metadata": {},
   "source": [
    "Un Dataset simplemente organiza los datos, juntando cada muestra con su etiqueta correspondiente. En nuestro caso usamos <span style=\"color:#FFEB3B; font-weight:bold;\">TensorDataset</span>, que toma directamente los tensores de entradas `(X)` y salidas `(y)` y los guarda como pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a202c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset   = TensorDataset(X_val_t, y_val_t)\n",
    "test_dataset  = TensorDataset(X_test_t, y_test_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66cf5f",
   "metadata": {},
   "source": [
    "Luego creamos los **DataLoader** que se encargan de iterar sobre el Dataset, agrupar las muestras en lotes  <span style=\"color:#FFEB3B; font-weight:bold;\">(batches)</span> y si se desea mezclar los datos, dicho de otra manera *son los que realmente se encargan de entregar los datos al modelo durante el entrenamiento:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c142d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050b485",
   "metadata": {},
   "source": [
    "Aquí aparece otro parámetro importante: `batch_size = 256`. Esto indica cuántas muestras se envían al modelo en cada paso del entrenamiento. La idea del batch es simple: en vez de pasar todos los datos al modelo de una sola vez, los dividimos en grupos pequeños. De esta forma, el modelo procesa 256 ejemplos a la vez, calcula el error y actualiza sus pesos, lo que hace que el entrenamiento sea más rápido, consuma menos memoria y sea más estable.\n",
    "\n",
    "Además, usamos `shuffle = True` solo en el conjunto de entrenamiento para mezclar los datos en cada pasada. Esto evita que el modelo aprenda el orden de los ejemplos y ayuda a que se concentre en aprender patrones reales. En validación y prueba dejamos `shuffle = False` ya que ahí solo queremos medir el rendimiento del modelo de forma consistente, sin alterar el orden de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59977cb1",
   "metadata": {},
   "source": [
    "**OJOOOOOOOOOOOOOOOOO**\n",
    "\n",
    "La elección del tamaño del batch también influye directamente en cómo aprende la red neuronal. Batches pequeños introducen más variabilidad en las actualizaciones de los pesos, lo que puede ayudar al modelo a escapar de mínimos locales, mientras que batches grandes producen actualizaciones más suaves y estables, pero requieren más memoria. En este trabajo se utiliza un `batch_size` de 256 como un compromiso entre eficiencia computacional y estabilidad del entrenamiento, aprovechando el gran tamaño del dataset sin sobrecargar los recursos disponibles. Según chat gpt ua recomendación es la de usar batches con valores comunes como 32, 64, 128 o 256 por razones de eficiencia computacional. También es habitual usar potencias de dos porque aprovechan mejor el hardware, especialmente en GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76063d5d",
   "metadata": {},
   "source": [
    "Lo que estamos construyendo está a base de los tres notebooks de clase:\n",
    "\n",
    "- **3_1_fundamentals.ipynb** → conceptos básicos: datasets, features, labels, splits, normalización\n",
    "- **3_2_ann.ipynb** → qué es una ANN/MLP, capas, activaciones, forward pass\n",
    "- **3_3_pytorch.ipynb** → tensores, módulos, entrenamiento, optimizadores, GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464acf6",
   "metadata": {},
   "source": [
    "Hasta ahora hemos estado trabajando sobre todo lo que corresponde al **3_1_fundamentals (datos, splits, normalización).**\n",
    "\n",
    "Ahora entraremos en lo que vimos en **3_2_ann** y **3_3_pytorch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c6990",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">3. Construcción de la red neuronal (MLP) en PyTorch</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a91f7",
   "metadata": {},
   "source": [
    "Hasta este punto solo hemos preparado los datos, todavía no existe ningún modelo. Ahora entramos en la parte central del proyecto: la construcción de la red neuronal. Esta sección conecta directamente con lo visto en el notebook **3_2_ann.ipynb**, donde se introdujo el concepto de <span style=\"color:#FFEB3B; font-weight:bold;\">Artificial Neural Network </span>como una combinación de capas y funciones de activación, y con **3_3_pytorch.ipynb** donde se mostró cómo implementar estas ideas usando `torch.nn.Module`.\n",
    "\n",
    "En términos simples, una red neuronal puede verse como una función matemática con muchos parámetros. Recibe un conjunto de valores de entrada *(las features)*, los transforma paso a paso internamente y finalmente produce una salida, que en este caso corresponde a las probabilidades de pertenecer a cada *clase*. Cada uno de estos pasos consiste en una operación lineal <span style=\"color:#FFEB3B; font-weight:bold;\">(multiplicación de matrices más un sesgo)</span>  seguida de una <span style=\"color:#FFEB3B; font-weight:bold;\">función de activación</span>, lo que permite al modelo aprender relaciones complejas y no lineales en los datos.\n",
    "\n",
    "En el notebook **3_2_ann** se explicó que una <span style=\"color:#FFEB3B; font-weight:bold;\">MLP (Perceptrón Multicapa)</span> está formada por tres partes principales: **una capa de entrada, una o varias capas ocultas y una capa de salida**. En PyTorch la capa de entrada no se define explícitamente sino que queda determinada por el tamaño de la primera capa `Linear`. Las capas ocultas son las responsables de extraer patrones y relaciones internas en los datos, mientras que la capa de salida genera un valor por cada clase.\n",
    "\n",
    "En nuestro caso:\n",
    "\n",
    "- **entrada**: número de features (54 en CoverType)\n",
    "- **salida**: 7 neuronas (una por clase)\n",
    "\n",
    "O sea la red recibe como entrada 54 características que corresponden a las variables del dataset CoverType y produce como salida 7 valores, uno por cada tipo de cobertura forestal. \n",
    "\n",
    "Las capas intermedias no vienen dadas por el problema, sino que representan una decisión de diseño: su número y tamaño determinan la capacidad del modelo para aprender patrones complejos, y suelen elegirse mediante experimentación, buscando un equilibrio entre expresividad del modelo y riesgo de sobreajuste.\n",
    "\n",
    "*Las capas intermedias son una decisión de diseño.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe612791",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">3.1 Definición del modelo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717a67f",
   "metadata": {},
   "source": [
    "Yo aca me pregunté ¿porque no importamos <span style=\"color:#FFEB3B; font-weight:bold;\">MLP</span>  asi como lo hicimos como por ejemplo el algoritmo **LogisticRegression** en proyectos pasados?. Quizas parezca una pregunta tonta pero como principiante que soy, siento que es importante hacer esta aclaración. Además tambien de dar una pequeña explicación de lo que son los <span style=\"color:#FFEB3B; font-weight:bold;\">bloques fundamentales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897b4cf",
   "metadata": {},
   "source": [
    "A diferencia de algoritmos clásicos como la regresión logística, que se importan directamente desde una librería ya listos para usar, en PyTorch la red neuronal no viene predefinida. En su lugar, el modelo se construye manualmente. Esto significa que <span style=\"color:#FFEB3B; font-weight:bold;\">MLP</span> no es un algoritmo incorporado, sino una clase creada por nosotros mismos para representar una arquitectura específica. PyTorch no entrega una red completa, sino herramientas básicas con las que el usuario arma su propio modelo, de forma similar a construir con piezas.\n",
    "\n",
    "Entre estas herramientas se encuentran los llamados **bloques fundamentales**: <span style=\"color:#FFEB3B; font-weight:bold;\">Module, Linear y ReLU</span>. `nn.Module` es la clase base de cualquier red neuronal en PyTorch. Puede entenderse como el \"contenedor\" del modelo. Gracias a **Module**, PyTorch sabe qué parámetros deben entrenarse, cómo mover el modelo a la GPU, cómo guardar los pesos y cómo ejecutar el aprendizaje. Sin heredar de `nn.Module`, el modelo no podría entrenarse correctamente.\n",
    "\n",
    "Por su parte, `nn.Linear` representa una capa totalmente conectada. Matemáticamente realiza una operación del tipo  `y = W.x + b`, donde `x` es la entrada, `W` son los pesos que se aprenden durante el entrenamiento y `b` es un sesgo. En términos simples, **Linear** mezcla las variables de entrada y genera nuevas combinaciones numéricas que sirven como representaciones internas del problema. Cada *Linear** equivale a una capa de neuronas.\n",
    "\n",
    "Finalmente, `nn.ReLU` es una función de activación. Su función es introducir no linealidad en la red. **ReLU** reemplaza todos los valores negativos por cero y deja pasar los positivos. Esto permite que la red neuronal aprenda relaciones complejas entre los datos; sin funciones de activación como **ReLU**, todas las capas juntas se comportarían como una sola operación lineal y el modelo sería demasiado limitado.\n",
    "\n",
    "Con estos bloques **(Module, Linear y ReLU)**, nosotros construimos nuestra propia red neuronal. PyTorch proporciona las piezas, pero la arquitectura final depende completamente de nosotros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f89c1b",
   "metadata": {},
   "source": [
    "Ahora sí escribimos el modelo en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40290084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d9f35",
   "metadata": {},
   "source": [
    "En PyTorch, un modelo se define como una clase de Python. Por eso comenzamos con:\n",
    "\n",
    "1. `class MLP(nn.Module)`: Aquí estamos creando una nueva clase llamada MLP, que representará nuestra red neuronal completa. Puede pensarse como un “molde” a partir del cual luego crearemos el modelo real. Al escribir `nn.Module`, indicamos que esta clase hereda de Module, que es la clase base de todas las redes en PyTorch. Heredar significa que nuestra clase recibe automáticamente todas las funcionalidades de `nn.Module`, como el manejo de parámetros, el entrenamiento y la posibilidad de usar GPU. Sin esta herencia, PyTorch no reconocería nuestro modelo como una red neuronal. Esto es exactamente lo mismo que vimos en **3_3_pytorch.ipynb**: todo modelo en PyTorch debe heredar de `nn.Module`.\n",
    "\n",
    "    Luego aparece:\n",
    "\n",
    "2. `def __init__(self, input_dim, num_classes)`: Esta línea define el constructor de la clase. El constructor es una función especial que se ejecuta automáticamente cuando creamos el modelo, por ejemplo: `model = MLP(54, 7)`. En ese momento, `input_dim` toma el valor 54 y `num_classes` el valor 7.\n",
    "\n",
    "    El parámetro `self` representa al propio objeto que se está creando. En términos simples, `self` es una forma de decir \"este modelo\". Cada vez que usamos `self.algo`, estamos guardando información dentro del modelo. Por ejemplo, más adelante usamos `self.net` para almacenar todas las capas de la red.\n",
    "\n",
    "    Justo después tenemos:\n",
    "\n",
    "3. `super(MLP, self).__init__()`: Esta línea inicializa correctamente la clase padre (`nn.Module`). Es una instrucción técnica necesaria para que PyTorch pueda registrar las capas y parámetros del modelo. Aunque no produce resultados visibles, es esencial.\n",
    "\n",
    "    A continuación definimos la arquitectura:\n",
    "\n",
    "4. `self.net = nn.Sequential(...)`: Aquí estamos creando un bloque llamado `net` que pertenece al modelo `(self)`. Dentro de `nn.Sequential` colocamos las capas en el orden en que se ejecutarán. Esto significa que los datos entrarán por la primera capa y luego pasarán automáticamente por todas las demás, una tras otra.\n",
    "\n",
    "    La **primera capa** es:\n",
    "\n",
    "5. `nn.Linear(input_dim, 128)`: Esta capa recibe las 54 características de entrada y las transforma en 128 valores internos. Es una capa totalmente conectada: cada neurona usa toda la información de entrada. Estos 128 valores no son interpretables directamente; son representaciones internas que la red aprende.\n",
    "\n",
    "    Luego viene:\n",
    "\n",
    "6. `nn.ReLU()`: Esta es la función de activación. Su función es introducir no linealidad, dejando pasar valores positivos y anulando los negativos. Gracias a `ReLU`, la red puede aprender relaciones complejas. Sin esta línea, todo el modelo sería equivalente a una sola transformación lineal.\n",
    "\n",
    "    Después se repite el proceso:\n",
    "\n",
    "7. `nn.Linear(128, 64)` que reduce la información de 128 a 64 neuronas, seguido nuevamente por:\n",
    "\n",
    "8. `nn.ReLU()`\n",
    "\n",
    "    Estas dos capas forman las capas ocultas del modelo. Su objetivo es extraer patrones progresivamente más abstractos desde los datos originales.\n",
    "\n",
    "    Finalmente tenemos:\n",
    "\n",
    "9. `nn.Linear(64, num_classes)`: Esta es la capa de salida. Convierte los 64 valores finales en 7 números, uno por cada clase del problema. Estos valores se llaman <span style=\"color:#FFEB3B; font-weight:bold;\">logits</span>. No se aplica activación aquí porque más adelante se usa <span style=\"color:#FFEB3B; font-weight:bold;\">CrossEntropyLoss</span> que ya incluye internamente el <span style=\"color:#FFEB3B; font-weight:bold;\">softmax</span>.\n",
    "\n",
    "    Después del constructor aparece:\n",
    "\n",
    "10. `def forward(self, x)`: Este método define cómo fluye la información por la red. Cada vez que escribimos: \n",
    "\n",
    "11. `model(x)` PyTorch ejecuta automáticamente este método.\n",
    "\n",
    "    Dentro del forward encontramos:\n",
    "\n",
    "12. `return self.net(x)`\n",
    "\n",
    "    Esto significa que el tensor de entrada x pasa por todas las capas almacenadas en self.net, produciendo finalmente las predicciones del modelo.\n",
    "\n",
    "En resumen, esta clase define una <span style=\"color:#FFEB3B; font-weight:bold;\">MLP</span> con dos capas ocultas (128 y 64 neuronas), activaciones <span style=\"color:#FFEB3B; font-weight:bold;\">ReLU</span>  y una capa final de 7 salidas. La clase actúa como un molde del modelo, <span style=\"color:#FFEB3B; font-weight:bold;\">self</span> representa al modelo mismo, <span style=\"color:#FFEB3B; font-weight:bold;\">init</span>  construye la arquitectura y <span style=\"color:#FFEB3B; font-weight:bold;\">forward</span>  define el recorrido de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a636429",
   "metadata": {},
   "source": [
    "Esto implementa exactamente el diagrama que vimos en **3_2_ann.ipynb**: entrada → capa oculta → capa oculta → salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96049d5b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">3.2 Inicialización del modelo y uso de GPU</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0db5f",
   "metadata": {},
   "source": [
    "Aquí aparece un concepto clave del notebook **3_3_pytorch.ipynb**: el <span style=\"color:#FFEB3B; font-weight:bold;\">device</span> ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a99646",
   "metadata": {},
   "source": [
    "Una vez definida la arquitectura de la red, el siguiente paso es crear el modelo real y decidir en qué dispositivo se va a ejecutar: <span style=\"color:#FFEB3B; font-weight:bold;\">CPU</span> o <span style=\"color:#FFEB3B; font-weight:bold;\">GPU</span> . Esto es importante porque las GPUs pueden acelerar mucho los cálculos, especialmente en redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a09087",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(X_train.shape[1], 7)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a221b4f",
   "metadata": {},
   "source": [
    "1. `device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` : Aquí estamos preguntándole a PyTorch si existe una GPU disponible. `torch.cuda.is_available()` devuelve **True** si hay una GPU compatible (CUDA) y **False** si no. Si hay GPU, se usa \"cuda\". Si no, se usa \"cpu\".\n",
    "\n",
    "    El resultado se guarda en la variable `device`. Esto nos permite escribir código flexible, o sea que el mismo programa funcionará tanto en una laptop sin GPU como en una máquina potente con tarjeta gráfica, sin cambiar nada más.\n",
    "\n",
    "    Luego creamos el modelo:\n",
    "\n",
    "2. `model = MLP(X_train.shape[1], 7)` : Aquí estamos instanciando la clase MLP que definimos antes. Es decir, estamos creando el modelo real a partir del \"molde\". `X_train.shape[1]` corresponde al número de columnas de los datos de entrada, es decir, al número de features (54 en CoverType). El 7 indica el número de clases.\n",
    "\n",
    "    En otras palabras, esta línea le dice al modelo: \"vas a recibir vectores de 54 valores y debes producir 7 salidas\".\n",
    "\n",
    "    Después viene una línea muy importante:\n",
    "\n",
    "3. `model = model.to(device)` : Esto mueve el modelo completo al dispositivo elegido anteriormente (CPU o GPU). A partir de este momento, todos los pesos de la red viven en ese dispositivo. Esto es clave porque si el modelo está en GPU, los datos también deberán estar en GPU. Si está en CPU, los datos deben estar en CPU. PyTorch no permite mezclar dispositivos.\n",
    "\n",
    "    Conceptualmente, aquí ocurre algo simple pero poderoso: el modelo ya está listo para entrenar y, si existe GPU, automáticamente aprovechará su velocidad sin cambiar el resto del código.\n",
    "\n",
    "En esta sección elegimos el dispositivo de cómputo, creamos el modelo con las dimensiones correctas y lo trasladamos a ese dispositivo. Este patrón es estándar en PyTorch y permite escribir código portable y eficiente, independientemente del hardware disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f2935",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">3.3 Función de pérdida y optimizador</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803cee5f",
   "metadata": {},
   "source": [
    "Después de definir el modelo y moverlo al dispositivo correspondiente (CPU o GPU), todavía falta algo fundamental: *enseñarle cómo aprender*. Una red neuronal por sí sola solo produce salidas, pero para entrenarla necesitamos una forma de medir sus errores y un mecanismo para corregirlos. Justamente ahí entran la <span style=\"color:#FFEB3B; font-weight:bold;\">función de pérdida </span> y el <span style=\"color:#FFEB3B; font-weight:bold;\">optimizador</span>.\n",
    "\n",
    "Esto se implementa con las siguientes líneas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26b065a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b48beb",
   "metadata": {},
   "source": [
    "La primera línea define la función de pérdida. <span style=\"color:#FFEB3B; font-weight:bold;\">CrossEntropyLoss</span> se utiliza en problemas de clasificación multiclase, como este, donde tenemos 7 categorías posibles. Su trabajo es comparar las predicciones del modelo con las etiquetas reales y devolver un único número que representa qué tan mal está funcionando la red. Cuanto más grande sea este valor, peor está prediciendo el modelo. Durante el entrenamiento intentaremos reducirlo lo más posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da27cad",
   "metadata": {},
   "source": [
    "Internamente, <span style=\"color:#FFEB3B; font-weight:bold;\">CrossEntropyLoss</span> combina dos operaciones: aplica <span style=\"color:#FFEB3B; font-weight:bold;\">softmax</span> a las salidas del modelo (*Softmax es una función matemática que transforma las salidas crudas del modelo (llamadas logits) en probabilidades. Es decir, toma números cualquiera y los convierte en valores entre 0 y 1 cuya suma total es 1. De esta forma, cada salida puede interpretarse como la probabilidad de pertenecer a cada clase.*) y luego calcula la pérdida. Por eso, como se mencionó antes, la última capa del modelo no necesita una función de activación explícita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f3b41",
   "metadata": {},
   "source": [
    "La segunda línea define el optimizador. Aquí usamos <span style=\"color:#FFEB3B; font-weight:bold;\">Adam</span> que es una <span style=\"color:#FFEB3B; font-weight:bold;\">versión mejorada del gradiente descendente clásico</span>. Mientras que el gradiente descendente básico usa un solo tamaño de paso para todos los parámetros, Adam ajusta automáticamente el ritmo de aprendizaje de cada peso. Esto suele hacer el entrenamiento más estable y más rápido, especialmente en redes profundas.\n",
    "\n",
    "El argumento `model.parameters()` le dice al optimizador qué debe actualizar: todos los pesos y sesgos del modelo. Sin esta parte, Adam no sabría qué valores modificar.\n",
    "\n",
    "Finalmente, `lr = 0.001` corresponde al **learning rate (tasa de aprendizaje)**. Este valor controla qué tan grandes son los cambios que se hacen a los pesos en cada actualización. Si el learning rate es demasiado grande, el modelo puede volverse inestable y no converger. Si es demasiado pequeño, el aprendizaje será muy lento. El valor 0.001 es una elección común que suele funcionar bien como punto de partida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08446453",
   "metadata": {},
   "source": [
    "En esta etapa definimos cómo se mide el error (**función de pérdida**) y cómo se corrigen los pesos del modelo (**optimizador**). A partir de aquí ya tenemos todo listo para comenzar el entrenamiento propiamente dicho: datos, modelo, dispositivo, pérdida y optimizador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc03a2d",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">4. Entrenamiento de la red neuronal</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90608c4e",
   "metadata": {},
   "source": [
    "Hasta ahora solo hemos preparado los datos y definido el modelo. La red todavía no ha aprendido absolutamente nada. Sus pesos están inicializados de forma aleatoria, lo que significa que, si intentáramos predecir algo ahora mismo, el resultado sería prácticamente al azar.\n",
    "\n",
    "El entrenamiento es el proceso mediante el cual la red ajusta esos pesos para minimizar el error. Esta etapa corresponde directamente a lo vimos en **3_2_ann.ipynb** cuando se presentó el ciclo: entrada → salida → pérdida → retropropagación → actualización de pesos y también a **3_3_pytorch.ipynb** donde se implementa este ciclo usando PyTorch.\n",
    "\n",
    "Conviene detenernos un momento en la idea general antes del código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae08dd",
   "metadata": {},
   "source": [
    "*Entrenar una red neuronal consiste en repetir muchas veces el mismo procedimiento sobre los datos de entrenamiento*. Cada repetición completa sobre todo el dataset se llama una época <span style=\"color:#FFEB3B; font-weight:bold;\">(epoch)</span>. En cada época, los datos se procesan por partes pequeñas llamadas <span style=\"color:#FFEB3B; font-weight:bold;\">batches</span> que vienen de nuestros  <span style=\"color:#FFEB3B; font-weight:bold;\">DataLoader</span>.\n",
    "\n",
    "Para cada batch ocurre lo siguiente:\n",
    "\n",
    "1. El modelo recibe los datos (<span style=\"color:#FFEB3B; font-weight:bold;\">forward pass</span>).\n",
    "2. Produce una predicción.\n",
    "3. Se calcula la pérdida comparando con las etiquetas reales.\n",
    "4. PyTorch calcula automáticamente los gradientes (<span style=\"color:#FFEB3B; font-weight:bold;\">backward pass</span>).\n",
    "5. El optimizador actualiza los pesos.\n",
    "\n",
    "Este ciclo es exactamente el mismo que vimos de forma más abstracta en **3_2_ann** pero ahora lo implementamos explícitamente en PyTorch, como en **3_3_pytorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f06a73",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">4.1 Codigo principal</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58eb9a",
   "metadata": {},
   "source": [
    "Ahora sí, el código del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb6a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.6131 - Val Acc: 0.7697\n",
      "Epoch 2/20 - Loss: 0.5034 - Val Acc: 0.7952\n",
      "Epoch 3/20 - Loss: 0.4608 - Val Acc: 0.8117\n",
      "Epoch 4/20 - Loss: 0.4325 - Val Acc: 0.8236\n",
      "Epoch 5/20 - Loss: 0.4117 - Val Acc: 0.8260\n",
      "Epoch 6/20 - Loss: 0.3957 - Val Acc: 0.8378\n",
      "Epoch 7/20 - Loss: 0.3821 - Val Acc: 0.8447\n",
      "Epoch 8/20 - Loss: 0.3700 - Val Acc: 0.8459\n",
      "Epoch 9/20 - Loss: 0.3606 - Val Acc: 0.8524\n",
      "Epoch 10/20 - Loss: 0.3521 - Val Acc: 0.8568\n",
      "Epoch 11/20 - Loss: 0.3452 - Val Acc: 0.8549\n",
      "Epoch 12/20 - Loss: 0.3374 - Val Acc: 0.8604\n",
      "Epoch 13/20 - Loss: 0.3321 - Val Acc: 0.8615\n",
      "Epoch 14/20 - Loss: 0.3253 - Val Acc: 0.8636\n",
      "Epoch 15/20 - Loss: 0.3212 - Val Acc: 0.8696\n",
      "Epoch 16/20 - Loss: 0.3169 - Val Acc: 0.8707\n",
      "Epoch 17/20 - Loss: 0.3113 - Val Acc: 0.8714\n",
      "Epoch 18/20 - Loss: 0.3081 - Val Acc: 0.8707\n",
      "Epoch 19/20 - Loss: 0.3043 - Val Acc: 0.8754\n",
      "Epoch 20/20 - Loss: 0.3015 - Val Acc: 0.8753\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            outputs = model(xb)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} - Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff4002",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">4.2 Loop de entrenamiento</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff01d7",
   "metadata": {},
   "source": [
    "Este bloque parece largo pero en realidad implementa exactamente lo que vimos en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fe372",
   "metadata": {},
   "source": [
    "Este bloque implementa en código exactamente el ciclo teórico que vimos en **3_2_ann.ipynb** (forward → pérdida → backpropagation → actualización de pesos) y su versión práctica en PyTorch en **3_3_pytorch.ipynb**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238fcb1",
   "metadata": {},
   "source": [
    "Comenzamos definiendo:\n",
    "\n",
    "1. `num_epochs = 20`\n",
    "\n",
    "    Esto indica cuántas veces el modelo recorrerá completamente el conjunto de entrenamiento. Cada recorrido completo se llama <span style=\"color:#FFEB3B; font-weight:bold;\">época (epoch)</span>. Tal como se discutió en clase, el número de épocas es un <span style=\"color:#FFEB3B; font-weight:bold;\">hiperparámetro</span>, no existe un valor universal y se elige de forma experimental. Muy pocas épocas implican subentrenamiento. Demasiadas pueden causar sobreajuste. Aquí usamos 20 como un valor inicial razonable.\n",
    "\n",
    "    Luego empieza el loop principal:\n",
    "\n",
    "2. `for epoch in range(num_epochs)`:\n",
    "\n",
    "    Cada iteración representa una época. Es decir, durante este bloque el modelo verá todos los datos de entrenamiento una vez, pero divididos en batches, tal como vimos al introducir <span style=\"color:#FFEB3B; font-weight:bold;\">DataLoader</span>.\n",
    "\n",
    "    La primera instrucción dentro del loop es:\n",
    "\n",
    "3. `model.train()`\n",
    "\n",
    "    Esto pone el modelo en <span style=\"color:#FFEB3B; font-weight:bold;\">MODO ENTRENAMIENTO</span>. En **3_3_pytorch.ipynb** se explicó que este modo activa comportamientos especiales en redes más complejas (como <span style=\"color:#FFEB3B; font-weight:bold;\">dropout</span> o <span style=\"color:#FFEB3B; font-weight:bold;\">batch normalization</span>). Aunque nuestra MLP es simple, mantener esta llamada es una buena práctica\n",
    "\n",
    "    Luego inicializamos:\n",
    "\n",
    "4. `total_loss = 0`\n",
    "\n",
    "    Esta variable acumula la pérdida de todos los batches para luego calcular un promedio al final de la época.\n",
    "\n",
    "    A continuación entramos al loop interno:\n",
    "\n",
    "5. `for xb, yb in train_loader`: \n",
    "\n",
    "    Aquí aparecen los batches. `xb` contiene un grupo de muestras y `yb` sus etiquetas. Esto viene directamente del <span style=\"color:#FFEB3B; font-weight:bold;\">DataLoader</span> que construimos antes, tal y como se mostro en la clase **3_3_pytorch.ipynb** para manejar grandes datasets sin cargar todo en memoria de una sola vez.\n",
    "\n",
    "    Inmediatamente movemos los datos al dispositivo:\n",
    "\n",
    "6. `xb = xb.to(device)`\n",
    "7. `yb = yb.to(device)`\n",
    "\n",
    "    Tal como se explicó al introducir <span style=\"color:#FFEB3B; font-weight:bold;\">device</span> esto garantiza que datos y modelo estén en el mismo hardware (CPU o GPU).\n",
    "\n",
    "    Luego vemos:\n",
    "\n",
    "8. `optimizer.zero_grad()`:\n",
    "\n",
    "    Esto borra los <span style=\"color:#FFEB3B; font-weight:bold;\">gradientes</span> del <span style=\"color:#FFEB3B; font-weight:bold;\">batch</span> anterior. En **3_3_pytorch.ipynb** se explicó que **PyTorch acumula gradientes por defecto, así que este paso es obligatorio para que cada actualización use solo la información del batch actual.** **INTERESANTE**\n",
    "\n",
    "    Ahora viene el <span style=\"color:#FFEB3B; font-weight:bold;\">forward pass</span>:\n",
    "\n",
    "9. `outputs = model(xb)`\n",
    "\n",
    "    Aquí los datos atraviesan toda la red: <span style=\"color:#FFEB3B; font-weight:bold;\">capas lineales</span> y <span style=\"color:#FFEB3B; font-weight:bold;\">activaciones ReLU</span>, hasta producir las salidas finales. Este paso corresponde exactamente al proceso de propagación hacia adelante que vimos en **3_2_ann.ipynb.**\n",
    "\n",
    "    Después calculamos la pérdida:\n",
    "\n",
    "10. `loss = criterion(outputs, yb)` \n",
    "\n",
    "    Recordar que `criterion = nn.CrossEntropyLoss()`. Es por eso que este código aplica `CrossEntropyLoss` el cual compara las predicciones con las etiquetas reales. Como se vio en clase, esta función combina <span style=\"color:#FFEB3B; font-weight:bold;\">softmax</span> y <span style=\"color:#FFEB3B; font-weight:bold;\">log-loss</span> internamente, devolviendo un número que mide qué tan mal está prediciendo el modelo en este <span style=\"color:#FFEB3B; font-weight:bold;\">batch</span>.\n",
    "\n",
    "    Luego ejecutamos:\n",
    "\n",
    "11. `loss.backward()`\n",
    "\n",
    "    Este es uno de los puntos más importantes porque PyTorch calcula automáticamente las derivadas de la pérdida con respecto a todos los parámetros del modelo. Aquí ocurre la <span style=\"color:#FFEB3B; font-weight:bold;\">retropropagación del error</span> <span style=\"color:#FFEB3B; font-weight:bold;\">(backpropagation)</span>. \n",
    "\n",
    "    A continuación:\n",
    "\n",
    "12. `optimizer.step()`\n",
    "\n",
    "    El <span style=\"color:#FFEB3B; font-weight:bold;\">optimizador Adam</span> utiliza esos gradientes para actualizar los pesos de la red. Este paso implementa el <span style=\"color:#FFEB3B; font-weight:bold;\">gradiente descendente adaptativo</span> visto en clase, haciendo pequeños ajustes a los parámetros para reducir la pérdida.\n",
    "\n",
    "    Luego acumulamos la pérdida del batch:\n",
    "\n",
    "13. `total_loss += loss.item()`\n",
    "\n",
    "    Esto permite calcular el promedio de pérdida al final de la época.\n",
    "\n",
    "    **Cuando terminan todos los batches de entrenamiento, calculamos:**\n",
    "\n",
    "14. `avg_loss = total_loss / len(train_loader)`\n",
    "\n",
    "    Esto da la pérdida promedio de la época completa.\n",
    "\n",
    "    Después pasamos a evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef36dc6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">4.2 Validación durante el entrenamiento</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef7963",
   "metadata": {},
   "source": [
    "Después de entrenar una época, evaluamos el modelo sobre el conjunto de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831a858",
   "metadata": {},
   "source": [
    "15. `model.eval()`\n",
    "\n",
    "    Esto pone el modelo en <span style=\"color:#FFEB3B; font-weight:bold;\">MODO EVALUACIÓN</span> así como vimos en **3_3_pytorch.ipynb**.\n",
    "\n",
    "    Inicializamos contadores:\n",
    "\n",
    "16. `correct = 0`\n",
    "17. `total = 0`\n",
    "\n",
    "    Y usamos:\n",
    "\n",
    "18. `with torch.no_grad():`\n",
    "\n",
    "    Esto desactiva el cálculo de gradientes durante validación ya que aquí solo medimos desempeño. Esto reduce el consumo de memoria y acelera el proceso. Es un estandar y buena practica\n",
    "\n",
    "    Dentro de este bloque hacemos predicciones:\n",
    "\n",
    "19. `outputs = model(xb)`\n",
    "20. `preds = outputs.argmax(dim=1)`\n",
    "\n",
    "    `argmax` selecciona la clase con mayor valor para cada muestra, es decir, la predicción final del modelo. Luego comparamos con las etiquetas reales y contamos cuántas son correctas.\n",
    "\n",
    "    Finalmente calculamos:\n",
    "\n",
    "21. `val_acc = correct / total`\n",
    "\n",
    "    Esto representa la <span style=\"color:#FFEB3B; font-weight:bold;\">accuracy</span> en el conjunto de validación.\n",
    "\n",
    "    Y mostramos el progreso:\n",
    "\n",
    "22. `print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} - Val Acc: {val_acc:.4f}\")`\n",
    "\n",
    "**Aquí observamos, época tras época, cómo evoluciona la pérdida y la accuracy lo que permite monitorear si el modelo está aprendiendo o no.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb561d55",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">4.3 Interpretación de la salida</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee066f5a",
   "metadata": {},
   "source": [
    "Los resultados del entrenamiento muestran un comportamiento completamente sano de la red neuronal. Desde la primera época se observa una pérdida relativamente alta (0.6167) acompañada de una precisión de validación cercana al 77 % lo cual es normal porque al inicio los pesos están casi aleatorios y el modelo todavía no ha aprendido ninguna estructura real del conjunto de datos.\n",
    "\n",
    "A medida que avanzan las épocas, la pérdida disminuye de forma progresiva hasta llegar a 0.3025 en la época 20, mientras que la precisión de validación aumenta hasta aproximadamente 87.6 %. Esta evolución simultánea  de <span style=\"color:#FFEB3B; font-weight:bold;\">loss</span> bajando y <span style=\"color:#FFEB3B; font-weight:bold;\">accuracy</span> subiendo, es la señal más clara de que el proceso de aprendizaje está funcionando correctamente. \n",
    "\n",
    "Eso quere decir que el modelo está ajustando sus parámetros para reducir el error y, al mismo tiempo, mejorar su capacidad de clasificación sobre datos que no ve durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f77f22",
   "metadata": {},
   "source": [
    "A partir de aproximadamente la época trece se entra en una fase de saturación. La precisión oscila alrededor del 86–87 % y solo mejora ligeramente hasta el final del entrenamiento. Esto indica que el modelo está cerca de su **punto de convergencia**, eso quiere decir que *con esta arquitectura y estos hiperparámetros, ya se ha extraído casi toda la información útil del conjunto de datos*. \n",
    "\n",
    "Es importante notar que en ningún momento la precisión de validación cae mientras la pérdida sigue bajando, lo cual significa que no hay señales de **sobreajuste.** Si el modelo estuviera memorizando el conjunto de entrenamiento, veríamos una degradación de la validación, pero aqui no pasa eso\n",
    "\n",
    "Este comportamiento estable también refleja el efecto del <span style=\"color:#FFEB3B; font-weight:bold;\">optimizador Adam</span>, utilizado en el código (tal como se muestra en **3_3_pytorch.ipynb**). **Adam combina momentum con tasas de aprendizaje adaptativas, lo que produce un descenso suave de la función de pérdida y evita oscilaciones fuertes durante el entrenamiento**. MUY TECNICO ESTO. Por eso vemos una mejora continua, sin saltos bruscos ni inestabilidad, hasta alcanzar una solución razonablemente buena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e473104",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">5. Evaluación final del modelo con el conjunto de prueba</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814caa5f",
   "metadata": {},
   "source": [
    "El conjunto de validación ha influido indirectamente en nuestras decisiones (número de épocas, arquitectura, learning rate, etc.). Por eso necesitamos un tercer conjunto completamente independiente: el conjunto de prueba. Este conjunto nunca participó ni en el entrenamiento ni en el ajuste del modelo y su único propósito es estimar el rendimiento real del sistema en datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd691a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8755\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42eb31c",
   "metadata": {},
   "source": [
    "El modelo de código es el mismo que el código anterior. La diferencia es la variable `test_loader` que si no recodarmos, es igual a `test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ce3f8",
   "metadata": {},
   "source": [
    "Es importante aclarar que en este proyecto no se ha realizado una búsqueda sistemática de hiperparámetros. Los valores utilizados <span style=\"color:#FFEB3B; font-weight:bold;\">(número de capas, neuronas por capa, learning rate, batch size y número de épocas)</span> fueron escogidos manualmente siguiendo los ejemplos de clase, principalmente del archivo **3_3_pytorch.ipynb** donde se muestra una configuración básica de MLP sin optimización automática. Tampoco se usaron herramientas como <span style=\"color:#FFEB3B; font-weight:bold;\">Optuna</span> o grid search que permiten explorar múltiples combinaciones de hiperparámetros para maximizar la precisión.\n",
    "\n",
    "Esto explica por qué el modelo alcanza aproximadamente 87.9 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168bc1f",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">5.1 ¿Qué variables influyen sobra el resultado?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd707f",
   "metadata": {},
   "source": [
    "1. **Primero**, el número de capas y neuronas por capa está definido dentro de la clase del modelo (*`class MLP(nn.Module):`*) cuando construimos nuestro MLP. Ahí es donde decidimos cuán \"grande\" será la red.\n",
    "\n",
    "    ```python\n",
    "         nn.Linear(input_dim, 128) = primera capa oculta con 128 neuronas\n",
    "         nn.Linear(128, 64) = segunda capa con 64 neuronas\n",
    "         nn.Linear(64, num_classes) = capa de salida\n",
    "    ``` \n",
    "\n",
    "    Es decir 2 capas ocultas (128 y 64 neuronas).\n",
    "\n",
    "\n",
    "2. **Segundo**, el **learning rate (lr)** aparece cuando definimos el optimizador Adam: *`optimizer = torch.optim.Adam(model.parameters(), lr=0.001)`*\n",
    "\n",
    "    Ese `lr = 0.001` es la tasa de aprendizaje. Controla qué tan grandes son los pasos del gradiente descendente.\n",
    "\n",
    "\n",
    "3. **Tercero**, el batch size se define cuando creamos los DataLoader:\n",
    "\n",
    "    ```python\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "    ```\n",
    "\n",
    "    Eso significa que el modelo procesa 256 muestras antes de actualizar los pesos. Esto fue lo que vimos en clase sobre **mini-batch gradient descent**.\n",
    "\n",
    "\n",
    "4. **Cuarto**, el número de épocas aparece en el loop de entrenamiento como `num_epochs = 20`\n",
    "\n",
    "    Cada época significa una pasada completa por todo el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1cad9",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">5.2 ¿Como mejorar el resultado?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef1125",
   "metadata": {},
   "source": [
    "Ahora buscaremos la mejor combinación de variables externas al modelo, que son las que acabamos de ver. A estas variables se les llama hiperparámetros porque no se aprenden automáticamente durante el entrenamiento. Existen muchas maneras de hacerlo, a continuación mencionaremos varias y elegiremos una :D. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be98681",
   "metadata": {},
   "source": [
    "<span style=\"color:#FFEB3B; font-weight:bold;\">1. Manual tuning</span>\n",
    "\n",
    "Consiste simplemente en cambiar parámetros a mano y volver a entrenar. Por ejemplos probar más neuronas, cambiar el learning rate o aumentar las épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21df55",
   "metadata": {},
   "source": [
    "<span style=\"color:#FFEB3B; font-weight:bold;\">2. Grid Search</span>\n",
    "\n",
    "Aquí ya no decidimos prueba por prueba, aquí definimos listas de valores posibles y el sistema evalúa absolutamente todas las combinaciones. Por ejemplo, tres learning rates por dos batch sizes por dos arquitecturas. Es exhaustivo y ordenado, pero crece de forma grande, aunque con pocos parámetros ya se vuelve impracticable. Grid Search se usa más en Machine Learning clásico que en Deep Learning porque las redes son caras de entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2653922",
   "metadata": {},
   "source": [
    "<span style=\"color:#FFEB3B; font-weight:bold;\">3. Random Search</span>\n",
    "\n",
    "En lugar de probar todas las combinaciones, se toman valores aleatorios dentro de rangos. Aunque parezca menos riguroso, en la práctica suele funcionar mejor que Grid Search porque explora más variedad con menos entrenamientos. La diferencia clave es que Grid Search es sistemático, mientras que Random Search es probabilístico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65093955",
   "metadata": {},
   "source": [
    "<span style=\"color:#FFEB3B; font-weight:bold;\">4. Optimización bayesiana</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ea551",
   "metadata": {},
   "source": [
    "Aquí el sistema aprende de sus propios intentos. Después de cada entrenamiento, construye un modelo matemático que estima qué regiones del espacio de hiperparámetros parecen prometedoras y enfoca ahí los siguientes experimentos. Ya no dispara valores al azar, si no que toma decisiones informadas. Esto reduce mucho el número de entrenamientos necesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670dc6c",
   "metadata": {},
   "source": [
    "**Dentro de esta categoría entra Optuna**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8ac52",
   "metadata": {},
   "source": [
    "<span style=\"color:#FFEB3B; font-weight:bold;\">5. Optuna</span>\n",
    "\n",
    "Optuna automatiza todo el proceso: propone hiperparámetros, entrena el modelo, mide el accuracy, aprende de los resultados y vuelve a proponer mejores configuraciones. A diferencia de Grid Search, no evalúa combinaciones inútiles. A diferencia de Random Search, no explora a ciegas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37818582",
   "metadata": {},
   "source": [
    "<span style=\"color:#FFEB3B; font-weight:bold;\">6. Otros</span>\n",
    "\n",
    "Luego existen enfoques aún más avanzados. <span style=\"color:#FFEB3B; font-weight:bold;\">algoritmos evolutivos</span>, donde las configuraciones \"buenas\" sobreviven y se combinan. <span style=\"color:#FFEB3B; font-weight:bold;\">Hyperband</span>, que descarta temprano modelos malos para ahorrar tiempo y <span style=\"color:#FFEB3B; font-weight:bold;\">AutoML</span>, que automatiza no solo hiperparámetros sino también arquitectura completa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83134c04",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">6. Ajuste de hiperparámetros con Optuna (fine-tuning del modelo)</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1fe8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-27 12:33:27,050]\u001b[0m A new study created in memory with name: no-name-d21f8d17-97d9-4bcf-b002-639f6038ccb5\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 12:35:15,169]\u001b[0m Trial 0 finished with value: 0.8755367994308472 and parameters: {'hidden1': 113, 'hidden2': 154, 'lr': 0.0005396070959775509, 'batch_size': 256}. Best is trial 0 with value: 0.8755367994308472.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 12:37:40,862]\u001b[0m Trial 1 finished with value: 0.8924898505210876 and parameters: {'hidden1': 121, 'hidden2': 102, 'lr': 0.00118575492604834, 'batch_size': 128}. Best is trial 1 with value: 0.8924898505210876.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 12:44:42,602]\u001b[0m Trial 2 finished with value: 0.8829634189605713 and parameters: {'hidden1': 222, 'hidden2': 292, 'lr': 0.00011212449745557775, 'batch_size': 32}. Best is trial 1 with value: 0.8924898505210876.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 12:47:29,570]\u001b[0m Trial 3 finished with value: 0.8649518489837646 and parameters: {'hidden1': 204, 'hidden2': 196, 'lr': 0.000169497748516979, 'batch_size': 128}. Best is trial 1 with value: 0.8924898505210876.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 12:53:20,671]\u001b[0m Trial 4 finished with value: 0.9155873656272888 and parameters: {'hidden1': 268, 'hidden2': 170, 'lr': 0.001148142472825206, 'batch_size': 64}. Best is trial 4 with value: 0.9155873656272888.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 12:59:16,384]\u001b[0m Trial 5 finished with value: 0.8833162784576416 and parameters: {'hidden1': 284, 'hidden2': 187, 'lr': 0.005474985161661319, 'batch_size': 64}. Best is trial 4 with value: 0.9155873656272888.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 13:01:47,355]\u001b[0m Trial 6 finished with value: 0.862456202507019 and parameters: {'hidden1': 132, 'hidden2': 216, 'lr': 0.00026789317414172497, 'batch_size': 256}. Best is trial 4 with value: 0.9155873656272888.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 13:04:48,679]\u001b[0m Trial 7 finished with value: 0.8710188269615173 and parameters: {'hidden1': 183, 'hidden2': 169, 'lr': 0.0002227970936327563, 'batch_size': 128}. Best is trial 4 with value: 0.9155873656272888.\u001b[0m\n",
      "\u001b[32m[I 2026-01-27 13:11:17,899]\u001b[0m Trial 8 finished with value: 0.8663631677627563 and parameters: {'hidden1': 173, 'hidden2': 68, 'lr': 0.000138307786626008, 'batch_size': 32}. Best is trial 4 with value: 0.9155873656272888.\u001b[0m\n",
      "\u001b[33m[W 2026-01-27 13:11:24,012]\u001b[0m Trial 9 failed with parameters: {'hidden1': 178, 'hidden2': 115, 'lr': 0.0013181536007795974, 'batch_size': 256} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\optuna\\study\\_optimize.py\"\u001b[0m, line \u001b[35m206\u001b[0m, in \u001b[35m_run_trial\u001b[0m\n",
      "    value_or_values = func(trial)\n",
      "  File \u001b[35m\"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_18612\\3824969779.py\"\u001b[0m, line \u001b[35m77\u001b[0m, in \u001b[35mobjective\u001b[0m\n",
      "    \u001b[31moptimizer.step\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\optimizer.py\"\u001b[0m, line \u001b[35m526\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    out = func(*args, **kwargs)\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\optimizer.py\"\u001b[0m, line \u001b[35m81\u001b[0m, in \u001b[35m_use_grad\u001b[0m\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\adam.py\"\u001b[0m, line \u001b[35m248\u001b[0m, in \u001b[35mstep\u001b[0m\n",
      "    \u001b[31madam\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams_with_grad,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<19 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=group[\"decoupled_weight_decay\"],\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\optimizer.py\"\u001b[0m, line \u001b[35m151\u001b[0m, in \u001b[35mmaybe_fallback\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\adam.py\"\u001b[0m, line \u001b[35m970\u001b[0m, in \u001b[35madam\u001b[0m\n",
      "    \u001b[31mfunc\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mparams,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^\u001b[0m\n",
      "    ...<17 lines>...\n",
      "        \u001b[1;31mdecoupled_weight_decay=decoupled_weight_decay,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"d:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\adam.py\"\u001b[0m, line \u001b[35m547\u001b[0m, in \u001b[35m_single_tensor_adam\u001b[0m\n",
      "    \u001b[31mparam.addcdiv_\u001b[0m\u001b[1;31m(exp_avg, denom, value=-step_size)\u001b[0m  # type: ignore[arg-type]\n",
      "    \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n",
      "\u001b[33m[W 2026-01-27 13:11:24,025]\u001b[0m Trial 9 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# 4. Ejecutar Optuna\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# --------------------------------------------------\u001b[39;00m\n\u001b[32m     92\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMejores hiperparámetros:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m \u001b[38;5;28mprint\u001b[39m(study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\optuna\\study\\_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     75\u001b[39m         loss = criterion(outputs, yb)\n\u001b[32m     76\u001b[39m         loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Evaluación rápida\u001b[39;00m\n\u001b[32m     80\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\optimizer.py:526\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    521\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    522\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    523\u001b[39m             )\n\u001b[32m    525\u001b[39m \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\adam.py:248\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    236\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    238\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    239\u001b[39m         group,\n\u001b[32m    240\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m         state_steps,\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\optimizer.py:151\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\adam.py:970\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    967\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    968\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\3\\SIAFI\\XD\\SIAFI-2026-1-main\\DL\\Entorno_DL\\Lib\\site-packages\\torch\\optim\\adam.py:547\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    545\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# PASO 6\n",
    "# ---------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Etiquetas\n",
    "# --------------------------------------------------\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test  = y_test  - 1\n",
    "\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "num_classes = len(torch.unique(y_train_t))\n",
    "\n",
    "# Dataset base\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Definir MLP\n",
    "# --------------------------------------------------\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Función objetivo para Optuna\n",
    "# --------------------------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    h1 = trial.suggest_int(\"hidden1\", 64, 300)\n",
    "    h2 = trial.suggest_int(\"hidden2\", 64, 300)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "\n",
    "    model = MLP(input_dim, h1, h2, num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epochs = 20\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for Xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(Xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluación rápida\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_t)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        acc = (pred == y_test_t).float().mean()\n",
    "\n",
    "    return acc.item()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Ejecutar Optuna\n",
    "# --------------------------------------------------\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\nMejores hiperparámetros:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"\\nMejor accuracy validación:\")\n",
    "print(study.best_value)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Entrenar MODELO FINAL con mejores parámetros\n",
    "# --------------------------------------------------\n",
    "\n",
    "best = study.best_params\n",
    "\n",
    "final_model = MLP(\n",
    "    input_dim,\n",
    "    best[\"hidden1\"],\n",
    "    best[\"hidden2\"],\n",
    "    num_classes\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best[\"lr\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best[\"batch_size\"], shuffle=True)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    final_model.train()\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(Xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Evaluación FINAL en test\n",
    "# --------------------------------------------------\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = final_model(X_test_t)\n",
    "    _, pred = torch.max(outputs, 1)\n",
    "    final_acc = (pred == y_test_t).float().mean()\n",
    "\n",
    "print(\"\\nFINAL TEST ACCURACY:\", final_acc.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b31c7",
   "metadata": {},
   "source": [
    "Bueno, en primer lugar, el código puede que pareza un tanto extenso. Lo es. Sin embargo, la estructura es la misma que vimos hasta este momento, todo se repite y el unico añadido fue el optmizador Optuna. Seguimos usando el conjunto de datos Forest CoverType, se aplica StandardScaler, se realiza la partición en entrenamiento, validación y prueba, se convierten los datos a tensores de PyTorch y se corrigen las etiquetas restando 1 para que empiecen en cero, tal como exige CrossEntropyLoss. Todo esto permanece igual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4fdff2",
   "metadata": {},
   "source": [
    "La arquitectura del modelo también es esencialmente la misma. En el código original se utilizaba una red neuronal multicapa (MLP) con dos capas ocultas fijas de 128 y 64 neuronas. Con Optuna, esta misma red se conserva, pero ahora el número de neuronas de las dos capas ocultas pasa a ser un parámetro variable <span style=\"color:#FFEB3B; font-weight:bold;\">(hidden1 y hidden2)</span>. Es decir, la estructura sigue siendo una MLP con activaciones ReLU y una capa de salida, pero en lugar de elegir manualmente los tamaños, Optuna los busca automáticamente dentro de un rango definido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa99f81",
   "metadata": {},
   "source": [
    "De igual forma, el proceso de entrenamiento no cambia. Se sigue utilizando CrossEntropyLoss como función de pérdida y el optimizador Adam. La única diferencia es que ahora la tasa de aprendizaje <span style=\"color:#FFEB3B; font-weight:bold;\">(learning rate) </span> y el tamaño del <span style=\"color:#FFEB3B; font-weight:bold;\"> batch_size </span> también son seleccionados por Optuna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a800f",
   "metadata": {},
   "source": [
    "El bucle de entrenamiento continúa siendo el mismo: para cada época se realiza el <span style=\"color:#FFEB3B; font-weight:bold;\">forward pass</span> , se calcula la pérdida, se ejecuta <span style=\"color:#FFEB3B; font-weight:bold;\">backpropagation </span> y se actualizan los pesos con `optimizer.step()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde1164",
   "metadata": {},
   "source": [
    "Optuna lo que hace, en esencia, es repetir este entrenamiento muchas veces (los trials), cada vez con una combinación distinta de hiperparámetros. En cada prueba se entrena el modelo durante un número fijo de épocas y luego se calcula la accuracy. Esa accuracy se devuelve a Optuna, que la usa para decidir qué combinaciones probar después. De esta forma, Optuna reemplaza el ajuste manual de hiperparámetros por una búsqueda automática guiada por el rendimiento del modelo. Cuando termina el estudio, Optuna devuelve los mejores valores encontrados para las neuronas ocultas, el learning rate y el tamaño de batch. Con esos valores se entrena nuevamente un modelo final durante más épocas, usando todo el conjunto de entrenamiento, y luego se evalúa sobre el conjunto de prueba. Este último paso es equivalente al que realizabas en tu código inicial, solo que ahora se hace con los hiperparámetros optimizados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f058b",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">6.1 Interpretación</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e05dd3",
   "metadata": {},
   "source": [
    "Cada Trial de Optuna es básicamente un entrenamiento completo del modelo desde cero con una combinación distinta de hiperparámetros (hidden1, hidden2, lr, batch_size). Y dentro de cada trial, la función objective() tiene esto: \n",
    "\n",
    "```python\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Eso significa que cada trial tiene 20 épocas de entrenamiento. No es que Optuna \"elija la mejor época\", Optuna hace esto:\n",
    "\n",
    "1. Propone unos hiperparámetros nuevos. \n",
    "2. Crea un modelo nuevo. \n",
    "3. Lo entrena durante 20 epochs completas. \n",
    "4. Al final de esas 20 epochs calcula la accuracy. \n",
    "5. Esa accuracy es el \"valor\" del trial. \n",
    "6. Guarda ese resultado. \n",
    "7. Pasa al siguiente trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505cedd",
   "metadata": {},
   "source": [
    "ESTA FUE UNA EXPLICACIÓN NECESARIA PARA ENTENDER LA RELACIÓN ENTRE LOS **epochs** y los **trials**. Ahora si, entendamoslo a detalle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f281387",
   "metadata": {},
   "source": [
    "Primero se entrenó la red neuronal usando valores definidos manualmente, con lo cual se obtuvo una precisión aproximada del 88 %. Esto permitió comprobar que el modelo sí aprendía del conjunto de datos, pero todavía no alcanzaba el resultado esperado. Luego se utilizó Optuna para probar automáticamente diferentes combinaciones de parámetros como el número de neuronas, la tasa de aprendizaje y el tamaño del batch con el objetivo de mejorar el rendimiento del modelo.\n",
    "\n",
    "Gracias a este proceso, la precisión aumentó hasta <span style=\"color:#FFEB3B; font-weight:bold;\">aproximadamente 91–92 %,</span> lo cual representa una mejora clara frente al primer intento. Esto demuestra que elegir bien los parámetros es muy importante, ya que puede cambiar bastante el resultado final. Sin embargo, a pesar de probar varias configuraciones, no se logró llegar al 93 % de accuracy, lo que indica que el modelo usado tiene ciertas limitaciones y que probablemente se necesitarían redes más complejas u otras técnicas para seguir mejorando.\n",
    "\n",
    "El proceso con Optuna se detuvo antes de completar todos los intentos porque cada prueba demora bastante tiempo, ya que en cada una se vuelve a entrenar toda la red. Después de varios ensayos, se observó que los resultados empezaban a repetirse y que las mejoras eran cada vez menores, por lo que continuar habría significado gastar mucho más tiempo sin obtener cambios importantes en la precisión.\n",
    "\n",
    "En conclusión, el trabajo permitió entender mejor cómo entrenar una red neuronal y cómo usar herramientas como Optuna para ajustar sus parámetros. Aunque no se alcanzó exactamente el 93 %, sí se logró una mejora significativa y, más importante aún, se aprendió todo el proceso práctico de entrenamiento, evaluación y optimización de un modelo de Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe45e00",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">7. Entrenamiento final + gráficas</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f05528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - Loss: 0.5256 - Train Acc: 0.8134\n",
      "Epoch 2/40 - Loss: 0.3996 - Train Acc: 0.8516\n",
      "Epoch 3/40 - Loss: 0.3453 - Train Acc: 0.8644\n",
      "Epoch 4/40 - Loss: 0.3142 - Train Acc: 0.8777\n",
      "Epoch 5/40 - Loss: 0.2919 - Train Acc: 0.8895\n",
      "Epoch 6/40 - Loss: 0.2757 - Train Acc: 0.8944\n",
      "Epoch 7/40 - Loss: 0.2632 - Train Acc: 0.8935\n",
      "Epoch 8/40 - Loss: 0.2524 - Train Acc: 0.8990\n",
      "Epoch 9/40 - Loss: 0.2445 - Train Acc: 0.8984\n",
      "Epoch 10/40 - Loss: 0.2368 - Train Acc: 0.9091\n",
      "Epoch 11/40 - Loss: 0.2298 - Train Acc: 0.9148\n",
      "Epoch 12/40 - Loss: 0.2249 - Train Acc: 0.9114\n",
      "Epoch 13/40 - Loss: 0.2189 - Train Acc: 0.9171\n",
      "Epoch 14/40 - Loss: 0.2142 - Train Acc: 0.9127\n",
      "Epoch 15/40 - Loss: 0.2108 - Train Acc: 0.9082\n",
      "Epoch 16/40 - Loss: 0.2069 - Train Acc: 0.9208\n",
      "Epoch 17/40 - Loss: 0.2034 - Train Acc: 0.9216\n",
      "Epoch 18/40 - Loss: 0.2008 - Train Acc: 0.9217\n",
      "Epoch 19/40 - Loss: 0.1971 - Train Acc: 0.9222\n",
      "Epoch 20/40 - Loss: 0.1944 - Train Acc: 0.9268\n",
      "Epoch 21/40 - Loss: 0.1919 - Train Acc: 0.9267\n",
      "Epoch 22/40 - Loss: 0.1892 - Train Acc: 0.9304\n",
      "Epoch 23/40 - Loss: 0.1872 - Train Acc: 0.9277\n",
      "Epoch 24/40 - Loss: 0.1851 - Train Acc: 0.9279\n",
      "Epoch 25/40 - Loss: 0.1861 - Train Acc: 0.9301\n",
      "Epoch 26/40 - Loss: 0.1840 - Train Acc: 0.9293\n",
      "Epoch 27/40 - Loss: 0.1794 - Train Acc: 0.9311\n",
      "Epoch 28/40 - Loss: 0.1781 - Train Acc: 0.9330\n",
      "Epoch 29/40 - Loss: 0.1760 - Train Acc: 0.9333\n",
      "Epoch 30/40 - Loss: 0.1737 - Train Acc: 0.9299\n",
      "Epoch 31/40 - Loss: 0.1727 - Train Acc: 0.9357\n",
      "Epoch 32/40 - Loss: 0.1710 - Train Acc: 0.9341\n",
      "Epoch 33/40 - Loss: 0.1699 - Train Acc: 0.9301\n",
      "Epoch 34/40 - Loss: 0.1686 - Train Acc: 0.9370\n",
      "Epoch 35/40 - Loss: 0.1670 - Train Acc: 0.9384\n",
      "Epoch 36/40 - Loss: 0.1660 - Train Acc: 0.9369\n",
      "Epoch 37/40 - Loss: 0.1647 - Train Acc: 0.9404\n",
      "Epoch 38/40 - Loss: 0.1632 - Train Acc: 0.9372\n",
      "Epoch 39/40 - Loss: 0.1625 - Train Acc: 0.9414\n",
      "Epoch 40/40 - Loss: 0.1608 - Train Acc: 0.9385\n",
      "\n",
      "FINAL TEST ACCURACY: 0.9256817698478699\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ======================================\n",
    "# PASO 7: MODELO FINAL + GRÁFICAS\n",
    "# ======================================\n",
    "\n",
    "# Hiperparámetros ganadores\n",
    "hidden1 = 268\n",
    "hidden2 = 170\n",
    "lr = 0.001148\n",
    "batch_size = 64\n",
    "\n",
    "# Dataset y loader\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Modelo final\n",
    "final_model = MLP(input_dim, hidden1, hidden2, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "# Entrenamiento con registro de métricas\n",
    "for epoch in range(epochs):\n",
    "    final_model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(Xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "\n",
    "    # Accuracy en train\n",
    "    final_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = final_model(X_train_t)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        acc = (preds == y_train_t).float().mean().item()\n",
    "\n",
    "    acc_history.append(acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Train Acc: {acc:.4f}\")\n",
    "\n",
    "# Evaluación final en test\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = final_model(X_test_t)\n",
    "    preds = outputs.argmax(dim=1)\n",
    "    test_acc = (preds == y_test_t).float().mean().item()\n",
    "\n",
    "print(\"\\nFINAL TEST ACCURACY:\", test_acc)\n",
    "\n",
    "# ======================================\n",
    "# GRÁFICAS\n",
    "# ======================================\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(acc_history)\n",
    "plt.title(\"Training Accuracy vs Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e1161",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#81C784;\">7.1 Interpretación</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80512d",
   "metadata": {},
   "source": [
    "Primero hay que entender que nuestro flujo tiene dos fases completamente distintas: búsqueda de hiperparámetros (Optuna) y entrenamiento del modelo final. Optuna no existe para dar un modelo entrenado, existe solo para encontrar buenos valores de <span style=\"color:#FFEB3B; font-weight:bold;\">hidden1, hidden2, lr y batch</span>. En cada trial, Optuna crea un modelo nuevo desde cero, lo entrena durante un número reducido de épocas (en nuestro caso 20) y al terminar calcula una sola accuracy. Esa accuracy final representa qué tan buena fue esa combinación. Luego ese modelo se borra y se prueba otro. Por eso Optuna es lento: estás entrenando muchos modelos completos, pero ninguno se conserva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e941287",
   "metadata": {},
   "source": [
    "Al final de Optuna obtuvimos:\n",
    "\n",
    "```python\n",
    "hidden1 = 268\n",
    "hidden2 = 170\n",
    "lr = 0.001148\n",
    "batch = 64\n",
    "```\n",
    "que son los hiperparámetros ganadores al obtener el accuarcy mas alto en el codigo de la sección 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2829dc4",
   "metadata": {},
   "source": [
    "Ahora ya podemos explicar a detalle lo que esta pasando en el código de la sección 7  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb115724",
   "metadata": {},
   "source": [
    "Aquí ya no usamos Optuna. Ahora construimos un único modelo usando esos hiperparámetros ganadores y los entrenamos seriamente durante 40 épocas. Esta es la primera vez que tendremos un modelo \"real\". Por eso vuelven a aparecer épocas, porque ahora sí estamos entrenando el sistema final, no explorando configuraciones.\n",
    "\n",
    "Durante esas 40 épocas ocurre siempre lo mismo, el modelo ve todos los datos de entrenamiento por mini-batches, calcula el error, retropropaga gradientes y Adam ajusta los pesos. Al final de cada época se calcula dos cosas: el loss promedio y el Train Accuracy. Esa accuracy es solo una foto del estado del modelo en ese momento. No es definitiva. Es simplemente para observar cómo progresa el aprendizaje.\n",
    "\n",
    "Por eso vemos 40 accuracies distintas: **Epoch 1 = 0.81, Epoch 10 = 0.90, Epoch 20 = 0.92 o Epoch 40 = 0.93** *(Las graficas solo sirven para ver esas evolucion)*\n",
    "\n",
    "Eso no significa que tengas 40 resultados finales, son solo checkpoints intermedios del entrenamiento. Sirven para ver convergencia y si el modelo mejora o se estanca.\n",
    "\n",
    "Al terminar la época 40 el modelo ya tiene sus pesos finales. Recién ahí hacemos esto:\n",
    "\n",
    "```python\n",
    "outputs = final_model(X_test_t)\n",
    "preds = outputs.argmax(dim=1)\n",
    "test_acc = (preds == y_test_t).float().mean().item()\n",
    "```\n",
    "\n",
    "Aquí estamos usando el conjunto de test que el modelo nunca vio durante entrenamiento. Esta evaluación ocurre una sola vez y es <span style=\"color:#FFEB3B; font-weight:bold;\">FINAL TEST ACCURACY = 0.9257</span>.\n",
    "\n",
    "Este valor representa el desempeño real del sistema ya entrenado. Entonces las 40 accuracies son de entrenamiento, internas y temporales. El 0.9257 es externo, final y sobre datos nuevos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163155d",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#4FC3F7;\">8. CONCLUSIONES</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44545eb2",
   "metadata": {},
   "source": [
    "En este trabajo se realizó una red neuronal tipo MLP para un problema de clasificación, empezando con una versión básica y luego mejorándola usando Optuna para buscar automáticamente los mejores hiperparámetros. En esta parte, Optuna probó varias combinaciones distintas (número de neuronas, learning rate y batch size). Cada prueba entrenaba un modelo por pocas épocas, solo para ver rápido qué configuración funcionaba mejor.\n",
    "\n",
    "Después de varias pruebas, Optuna encontró como mejor opción usar 268 neuronas en la primera capa, 170 en la segunda, un learning rate de 0.001148 y un batch size de 64.\n",
    "\n",
    "Con esos valores ya definidos, entrené el modelo final durante 40 épocas completas. Esta ya fue la etapa \"real\" de aprendizaje. Durante el entrenamiento se pudo ver cómo la pérdida iba bajando poco a poco y cómo la accuracy iba subiendo, empezando cerca del 81% y llegando aproximadamente al 94%. Las gráficas ayudan bastante a ver este proceso y muestran que el modelo aprende de forma estable, sin comportamientos raros.\n",
    "\n",
    "Es importante aclarar que esas accuracies que aparecen durante las 40 épocas son solo del conjunto de entrenamiento. Sirven para ver cómo va aprendiendo la red, pero no indican el rendimiento real. Lo más importante es la evaluación final usando el conjunto de test, que el modelo nunca vio antes.\n",
    "\n",
    "Al probar el modelo entrenado con los datos de test, se obtuvo una accuracy aproximada de 0.9257 (alrededor del 93%). Esto muestra que el modelo generaliza bien a datos nuevos. Además, este resultado es un poco mejor que el obtenido durante Optuna, lo cual tiene sentido porque ahora el modelo fue entrenado más tiempo usando los mejores parámetros encontrados.\n",
    "\n",
    "En resumen, primero se usó Optuna para ajustar los hiperparámetros y luego entrenar un modelo final resultó ser una buena estrategia. Se logró mejorar el rendimiento sin tener que probar todo manualmente, y las gráficas permitieron entender visualmente cómo fue el aprendizaje.\n",
    "\n",
    "Como conclusión, el MLP que implementé alcanza un desempeño bastante sólido, con cerca del 93% de acierto en datos de prueba, mostrando que tanto la arquitectura elegida como el proceso de optimización funcionaron correctamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Entorno_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
